{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-08T16:25:09.060804Z","iopub.status.busy":"2022-10-08T16:25:09.060049Z","iopub.status.idle":"2022-10-08T16:25:09.070580Z","shell.execute_reply":"2022-10-08T16:25:09.069457Z","shell.execute_reply.started":"2022-10-08T16:25:09.060757Z"},"id":"2xI8J4LyGFEd","outputId":"91df4321-82da-4f63-d523-91c4eed99731","trusted":true},"outputs":[],"source":["## Import all the necessary files modules and routines\n","import tensorflow\n","from sklearn.model_selection import train_test_split\n","from tensorflow import keras\n","import numpy as np\n","import pandas as pd\n","import pickle as pkl\n","tensorflow.keras.backend.clear_session()\n","from tensorflow.keras.layers import Concatenate\n","from keras.layers.convolutional import Conv2D, MaxPooling2D, UpSampling2D, ZeroPadding2D\n","from keras.layers import Input, add\n","from keras.models import Model\n","from matplotlib import image\n","from matplotlib import pyplot\n","from ipywidgets import interact\n","import matplotlib.pyplot as plt\n","from skimage.transform import resize\n","from numpy import genfromtxt\n","from tensorflow.keras.utils import to_categorical"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-08T16:25:11.014741Z","iopub.status.busy":"2022-10-08T16:25:11.014367Z","iopub.status.idle":"2022-10-08T16:25:11.255013Z","shell.execute_reply":"2022-10-08T16:25:11.253844Z","shell.execute_reply.started":"2022-10-08T16:25:11.014689Z"},"id":"yBOGrWs3Gmen","outputId":"b757ff3f-80eb-4f3b-c2af-7adb16b2a752","trusted":true},"outputs":[],"source":["\n","## Import Low Resolution images as np array and split in (32*32) format \n","Y=np.load('../input/dataset-new/Lowres.npy',allow_pickle=True)\n","\n","x_original=np.split(Y,945)\n","\n","# Plotting images for easy visualization of Structures\n","def plot_bridge(i):\n","    fig,ax = pyplot.subplots()\n","    im = pyplot.imshow(x_original[i], cmap='gray_r')\n","    pyplot.axis('off')\n","    \n","    pyplot.show()\n","\n","interact(plot_bridge, i=(0, len(x_original)-1))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-08T16:25:11.858404Z","iopub.status.busy":"2022-10-08T16:25:11.858050Z","iopub.status.idle":"2022-10-08T16:25:11.868807Z","shell.execute_reply":"2022-10-08T16:25:11.867613Z","shell.execute_reply.started":"2022-10-08T16:25:11.858375Z"},"trusted":true},"outputs":[],"source":["X_input=np.array(x_original)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-08T16:25:12.216223Z","iopub.status.busy":"2022-10-08T16:25:12.215542Z","iopub.status.idle":"2022-10-08T16:25:12.232409Z","shell.execute_reply":"2022-10-08T16:25:12.231137Z","shell.execute_reply.started":"2022-10-08T16:25:12.216185Z"},"id":"-uRTXSf6HKPa","outputId":"4b3f0909-fb6b-4b92-9803-dd250d9633bd","trusted":true},"outputs":[],"source":["X=np.array(x_original)\n","print(X.shape)\n","a=np.zeros((1,33))\n","X= np.insert(X, 0, 1, axis=2)\n","print(X[944])\n","print(X.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-08T16:25:12.490503Z","iopub.status.busy":"2022-10-08T16:25:12.489677Z","iopub.status.idle":"2022-10-08T16:25:12.528458Z","shell.execute_reply":"2022-10-08T16:25:12.527614Z","shell.execute_reply.started":"2022-10-08T16:25:12.490463Z"},"id":"fiOVXbkcJAJk","outputId":"6ca094ac-64d1-43be-d71d-0d6499bd1866","trusted":true},"outputs":[],"source":["# Creating zero valued multi- dimensional array of dimension (945*33*33) to accomdate Boundary conditions.\n","X_data=np.zeros((945,33,33))\n","print(a.shape)\n","for i in range(945):\n","    X_data[i]=np.append(X[i],a,axis=0)\n","print(X_data.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-08T16:25:12.720375Z","iopub.status.busy":"2022-10-08T16:25:12.719392Z","iopub.status.idle":"2022-10-08T16:25:12.727821Z","shell.execute_reply":"2022-10-08T16:25:12.726806Z","shell.execute_reply.started":"2022-10-08T16:25:12.720321Z"},"id":"PQz5FeICK0FF","outputId":"060dffe6-02cc-44b4-b41b-c4ae542af426","trusted":true},"outputs":[],"source":["# Creating a channel for consideration of X-directional fixed BC\n","X_data3=np.expand_dims(X_data,axis=3)\n","print(X_data3.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-08T16:25:12.935019Z","iopub.status.busy":"2022-10-08T16:25:12.934079Z","iopub.status.idle":"2022-10-08T16:25:12.944864Z","shell.execute_reply":"2022-10-08T16:25:12.943787Z","shell.execute_reply.started":"2022-10-08T16:25:12.934976Z"},"id":"3uo2yG8uOVjj","outputId":"ebc666e1-be6d-4aa8-cecb-bc536f8b1e38","trusted":true},"outputs":[],"source":["# Creating a channel for consideration of Y-directional fixed BC\n","X_data4=X_data3\n","print(X_data4.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-08T16:25:13.117432Z","iopub.status.busy":"2022-10-08T16:25:13.116952Z","iopub.status.idle":"2022-10-08T16:25:13.152341Z","shell.execute_reply":"2022-10-08T16:25:13.151172Z","shell.execute_reply.started":"2022-10-08T16:25:13.117396Z"},"id":"qsiys_l5RAin","trusted":true},"outputs":[],"source":["#Creating a channel for consideration of X-directional force BC\n","X_data1_temp= np.insert(x_original, 0, 0, axis=2)\n","X_data1=np.zeros((945,33,33))\n","for i in range(945):\n","    X_data1[i]=np.append(X_data1_temp[i],a,axis=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-08T16:25:13.312327Z","iopub.status.busy":"2022-10-08T16:25:13.311130Z","iopub.status.idle":"2022-10-08T16:25:13.319740Z","shell.execute_reply":"2022-10-08T16:25:13.318283Z","shell.execute_reply.started":"2022-10-08T16:25:13.312286Z"},"id":"XmXDNNK8VFT5","outputId":"7344e9de-3a30-408d-db81-158b68771aba","trusted":true},"outputs":[],"source":["#Creating a channel for consideration of Y-directional force BC\n","X_data2 = X_data1\n","for i in range(945):\n","    X_data2[i][32][32]=1\n","\n","X_data2=np.expand_dims(X_data2,axis=3)\n","print(X_data2.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-08T16:25:13.670760Z","iopub.status.busy":"2022-10-08T16:25:13.670382Z","iopub.status.idle":"2022-10-08T16:25:13.676931Z","shell.execute_reply":"2022-10-08T16:25:13.675212Z","shell.execute_reply.started":"2022-10-08T16:25:13.670722Z"},"id":"tdXEtJq3Rs0X","outputId":"1058e940-9121-43ac-bc0f-3f15a79ccdde","trusted":true},"outputs":[],"source":["X_data1=np.expand_dims(X_data1,axis=3)\n","print(X_data1.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-08T16:25:14.125342Z","iopub.status.busy":"2022-10-08T16:25:14.124649Z","iopub.status.idle":"2022-10-08T16:25:14.149957Z","shell.execute_reply":"2022-10-08T16:25:14.148781Z","shell.execute_reply.started":"2022-10-08T16:25:14.125307Z"},"id":"1ofVrD33UD7y","trusted":true},"outputs":[],"source":["#Concatenating all the individual channels (BCs) into one, creating final input \n","\n","X_final= np.concatenate((X_data1, X_data2,X_data3,X_data4),axis=3)\n","print(X_final.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-08T16:25:14.552537Z","iopub.status.busy":"2022-10-08T16:25:14.551381Z","iopub.status.idle":"2022-10-08T16:25:14.570107Z","shell.execute_reply":"2022-10-08T16:25:14.568991Z","shell.execute_reply.started":"2022-10-08T16:25:14.552496Z"},"id":"8gyLuOkYAFkL","outputId":"777c1e43-6524-4e10-ee7a-125adf32ecea","trusted":true},"outputs":[],"source":["#Importing Volume fraction \n","\n","my_data = genfromtxt('../input/dataset-new/input.csv', delimiter=',')[:,2]\n","my_data = my_data[0:945]\n","print(my_data[30:40])"]},{"cell_type":"markdown","metadata":{"id":"fUG2oQibfEVV"},"source":["**CNN AUTOENCODER**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-08T16:25:15.334317Z","iopub.status.busy":"2022-10-08T16:25:15.333961Z","iopub.status.idle":"2022-10-08T16:25:15.343541Z","shell.execute_reply":"2022-10-08T16:25:15.342445Z","shell.execute_reply.started":"2022-10-08T16:25:15.334287Z"},"id":"WZd-Hl0ccB6w","outputId":"5e26ba35-deb2-40f7-e5fe-620f82df4dfc","trusted":true},"outputs":[],"source":["# Creating volume fraction data\n","\n","X_data_parent=np.ones((105,4,4,1))\n","a1 = X_data_parent*0.1\n","a2= X_data_parent*0.2\n","a3= X_data_parent*0.3\n","a4= X_data_parent*0.4\n","a5= X_data_parent*0.5\n","a6= X_data_parent*0.6\n","a7= X_data_parent*0.7\n","a8= X_data_parent*0.8\n","a9= X_data_parent*0.9\n","abc=np.concatenate((a1,a2,a3,a4,a5,a6,a7,a8,a9),axis=0)\n","\n","print(abc.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-08T16:25:16.077801Z","iopub.status.busy":"2022-10-08T16:25:16.077422Z","iopub.status.idle":"2022-10-08T16:25:19.643165Z","shell.execute_reply":"2022-10-08T16:25:19.642052Z","shell.execute_reply.started":"2022-10-08T16:25:16.077769Z"},"id":"CULjaOSo4vhN","trusted":true},"outputs":[],"source":["#Creating encoder-decoder model\n","\n","start = Input(shape=(33, 33 ,4)) \n","\n","#ENCODER\n","conv1_1= Conv2D(64,(2,2),activation ='relu',strides=(1,1))(start)\n","conv1_2= Conv2D(64,(3,3),padding = \"same\",activation ='relu',strides=(1,1))(conv1_1)\n","pool1= MaxPooling2D(pool_size=(2,2))(conv1_2)\n","conv1_3= Conv2D(128,(3,3),padding = \"same\",activation ='relu',strides=(1,1))(pool1)\n","conv1_4= Conv2D(128,(3,3),padding = \"same\",activation ='relu',strides=(1,1))(conv1_3)\n","pool2= MaxPooling2D(pool_size=(2,2))(conv1_4)\n","conv1_5= Conv2D(256,(3,3),padding = \"same\",activation ='relu',strides=(1,1))(pool2)\n","conv1_6= Conv2D(256,(3,3),padding = \"same\",activation ='relu',strides=(1,1))(conv1_5)\n","pool3= MaxPooling2D(pool_size=(2,2))(conv1_6)\n","h= Conv2D(512,(3,3),strides=(1, 1),padding = 'same',activation ='relu')(pool3)\n","\n","label=Input(shape=(4,4,1))\n","\n","lat=Concatenate()([h,label])\n","\n","#DECODER\n","\n","conv2_1= Conv2D(512,(3,3),padding=\"same\",activation ='relu',strides=(1,1))(lat)\n","up1= UpSampling2D(size=(2,2))(conv2_1)\n","conv2_2= Conv2D(256,(3,3),padding = \"same\",activation ='relu',strides=(1,1))(up1)\n","conv2_3= Conv2D(256,(3,3),padding = \"same\",activation ='relu',strides=(1,1))(conv2_2)\n","up2= UpSampling2D(size=(2,2))(conv2_3)\n","conv2_4= Conv2D(128,(3,3),padding = \"same\",activation ='relu',strides=(1,1))(up2)\n","conv2_5= Conv2D(128,(3,3),padding = \"same\",activation ='relu',strides=(1,1))(conv2_4)\n","up3= UpSampling2D(size=(2,2))(conv2_5)\n","conv2_6= Conv2D(64,(3,3),padding = \"same\",activation ='relu',strides=(1,1))(up3)\n","conv2_7= Conv2D(2,(3,3),padding = \"same\",activation ='relu',strides=(1,1))(conv2_6)\n","r= Conv2D(1,(3,3),padding = \"same\",activation ='sigmoid',strides=(1,1))(conv2_7)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-08T16:25:19.645959Z","iopub.status.busy":"2022-10-08T16:25:19.645036Z","iopub.status.idle":"2022-10-08T16:25:19.669569Z","shell.execute_reply":"2022-10-08T16:25:19.668734Z","shell.execute_reply.started":"2022-10-08T16:25:19.645922Z"},"id":"jlPZumBejSLX","outputId":"f4e79f8d-f0eb-4185-d7c9-773b21be5e76","trusted":true},"outputs":[],"source":["#Assigning inputs and outputs to the autoencoder model and compiling the same\n","\n","autoencoder = Model(inputs=[start,label], outputs=r)\n","autoencoder.compile(optimizer='adam', loss='mae')\n","autoencoder.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-08T16:25:19.672830Z","iopub.status.busy":"2022-10-08T16:25:19.671670Z","iopub.status.idle":"2022-10-08T16:25:19.693226Z","shell.execute_reply":"2022-10-08T16:25:19.692095Z","shell.execute_reply.started":"2022-10-08T16:25:19.672795Z"},"id":"1H4i9PoV7HWF","outputId":"a379ccf0-35dc-46b3-a077-f27fd6604d82","trusted":true},"outputs":[],"source":["# test train split of training and validation data\n","\n","images_train, images_test,abc_train,abc_test = train_test_split(X_final,abc,train_size= 0.8,test_size=0.20,shuffle=False)\n","print(images_train.shape)\n","print(abc_train.shape)\n","\n","X_input_train = X_input[:756]\n","print(X_input_train.shape)\n","X_input_test = X_input[756:]\n","print(X_input_test.shape)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-08T16:25:19.695922Z","iopub.status.busy":"2022-10-08T16:25:19.695438Z","iopub.status.idle":"2022-10-08T16:25:33.558133Z","shell.execute_reply":"2022-10-08T16:25:33.557139Z","shell.execute_reply.started":"2022-10-08T16:25:19.695886Z"},"id":"AnZejjSn4fnv","outputId":"c5fa53f6-528a-4295-9cc2-7724f25a71da","trusted":true},"outputs":[],"source":["# Assigning Hyperparameters (batch size and epochs) and training the model\n","\n","epochs = 12\n","batch_size = 50\n","\n","history = autoencoder.fit([images_train,abc_train], X_input_train , batch_size=batch_size, epochs=epochs,verbose=1, validation_data=([images_test,abc_test],X_input_test))"]},{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2022-10-08T13:16:07.627981Z","iopub.status.busy":"2022-10-08T13:16:07.627610Z","iopub.status.idle":"2022-10-08T13:16:08.272027Z","shell.execute_reply":"2022-10-08T13:16:08.270898Z","shell.execute_reply.started":"2022-10-08T13:16:07.627944Z"},"id":"gmnsEgP2k0ki"},"source":["###### Predicting on test data\n","\n","decoded_imgs = autoencoder.predict([images_test, abc_test])\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-08T16:25:35.969065Z","iopub.status.busy":"2022-10-08T16:25:35.968622Z","iopub.status.idle":"2022-10-08T16:25:36.616701Z","shell.execute_reply":"2022-10-08T16:25:36.615711Z","shell.execute_reply.started":"2022-10-08T16:25:35.969032Z"},"trusted":true},"outputs":[],"source":["decoded_imgs = autoencoder.predict([images_test, abc_test])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-08T16:25:38.983732Z","iopub.status.busy":"2022-10-08T16:25:38.983309Z","iopub.status.idle":"2022-10-08T16:25:39.118399Z","shell.execute_reply":"2022-10-08T16:25:39.117179Z","shell.execute_reply.started":"2022-10-08T16:25:38.983671Z"},"id":"phLMdnLQraSp","outputId":"01d43a2e-33d5-472f-de91-f6f702e6da3e","trusted":true},"outputs":[],"source":["#Plotting interactive images of predicted images on test_data\n","\n","\n","def plot_bridge(i):\n","    fig,ax = pyplot.subplots()\n","    \n","    im = pyplot.imshow(decoded_imgs[i].reshape(32,32), cmap='gray_r')\n","    pyplot.axis('off')\n","    \n","    pyplot.show()\n","\n","interact(plot_bridge, i=(0, len(decoded_imgs)-1))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-08T16:25:47.210520Z","iopub.status.busy":"2022-10-08T16:25:47.210113Z","iopub.status.idle":"2022-10-08T16:25:47.333126Z","shell.execute_reply":"2022-10-08T16:25:47.331924Z","shell.execute_reply.started":"2022-10-08T16:25:47.210489Z"},"id":"rLlcrBUosQKV","outputId":"bf7275bd-101f-44d8-b9e6-5cbae1ba5b2d","trusted":true},"outputs":[],"source":["#Plotting interactive images of original images(ground truth) on test_data\n","\n","def plot_bridge1(i):\n","    fig,ax = pyplot.subplots()\n","    \n","    #print(f\"Volume fraction: {y[i]}\")\n","    im1 = pyplot.imshow(X_input_test[i].reshape(32,32), cmap='gray_r')\n","    pyplot.axis('off')\n","    \n","    pyplot.show()\n"," \n","interact(plot_bridge1, i=(0, len(X_input_test)-1))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-08T16:25:47.711329Z","iopub.status.busy":"2022-10-08T16:25:47.711000Z","iopub.status.idle":"2022-10-08T16:25:47.922597Z","shell.execute_reply":"2022-10-08T16:25:47.921651Z","shell.execute_reply.started":"2022-10-08T16:25:47.711300Z"},"id":"29Jg9G3Y76a2","outputId":"b9a3e28a-a3c7-4525-cd35-e2415e5b363b","trusted":true},"outputs":[],"source":["#Plotting training and validation losses against epoch\n","\n","print(history.history.keys())\n","\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('model loss')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'validation'], loc='upper right')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"6hI_BiwzsTVU"},"source":["## GAN "]},{"cell_type":"markdown","metadata":{"id":"GzgestIbsaIW"},"source":["Generator module\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-08T16:25:49.758041Z","iopub.status.busy":"2022-10-08T16:25:49.757284Z","iopub.status.idle":"2022-10-08T16:25:49.773286Z","shell.execute_reply":"2022-10-08T16:25:49.772374Z","shell.execute_reply.started":"2022-10-08T16:25:49.757996Z"},"id":"GhVJg1cRshFe","trusted":true},"outputs":[],"source":["#Importing all the necessary modules and routines for GAN\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","from PIL import Image\n","from PIL.ImageColor import getrgb\n","import glob\n","import os\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from tensorflow.keras import Input\n","from tensorflow.keras.applications import VGG19\n","from tensorflow.keras.callbacks import TensorBoard\n","from tensorflow.keras.layers import BatchNormalization, Activation, LeakyReLU, Add, Dense, Flatten\n","from tensorflow.keras.layers import Conv2D, UpSampling2D\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import Adam\n","import shutil\n","import datetime\n","%load_ext tensorboard"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-08T16:25:50.370427Z","iopub.status.busy":"2022-10-08T16:25:50.370074Z","iopub.status.idle":"2022-10-08T16:25:51.210264Z","shell.execute_reply":"2022-10-08T16:25:51.209041Z","shell.execute_reply.started":"2022-10-08T16:25:50.370398Z"},"id":"Ljzy6CDPvzjH","trusted":true},"outputs":[],"source":["#Predicting on full data set as it will be input to GAN\n","\n","input_GAN = autoencoder.predict([X_final,abc])\n","\n","def plot_bridge3(i):\n","    fig,ax = pyplot.subplots()\n","    \n","    im3 = pyplot.imshow(input_GAN[i].reshape(32,32), cmap='gray_r')\n","    pyplot.axis('off')\n","    \n","    pyplot.show()\n"," \n"," \n","interact(plot_bridge3, i=(0, len(input_GAN)-1))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-08T16:25:56.518902Z","iopub.status.busy":"2022-10-08T16:25:56.518536Z","iopub.status.idle":"2022-10-08T16:25:56.532091Z","shell.execute_reply":"2022-10-08T16:25:56.530822Z","shell.execute_reply.started":"2022-10-08T16:25:56.518872Z"},"id":"iF1usoMCDEst","trusted":true},"outputs":[],"source":["#Building generator network\n","\n","def build_generator():\n","   \n","    residual_blocks = 16\n","    input_shape = (32, 32, 1)\n","\n","    # Input Layer of the generator network\n","    input_layer = Input(shape=input_shape)\n","\n","    # Add the pre-residual block\n","    conv1_GeN = Conv2D(64,(5,5),activation ='relu',padding='same',strides=(1,1))(input_layer)\n","\n","    # Add the post-residual block\n","\n","    conv2_GeN= Conv2D(64,(3,3),padding = \"same\",activation ='relu',strides=(1,1))(conv1_GeN)\n","    conv3_GeN= Conv2D(64,(3,3),padding = \"same\",activation ='relu',strides=(1,1))(conv2_GeN)\n","    conv4_GeN= Conv2D(64,(3,3),padding = \"same\",activation ='relu',strides=(1,1))(conv3_GeN)\n","    conv5_GeN= Conv2D(64,(3,3),padding = \"same\",activation ='relu',strides=(1,1))(conv4_GeN)\n","    conv6_GeN= Conv2D(64,(3,3),padding = \"same\",activation ='relu',strides=(1,1))(conv5_GeN)\n","    conv7_GeN= Conv2D(64,(3,3),padding = \"same\",activation ='relu',strides=(1,1))(conv6_GeN)\n","    conv8_GeN= Conv2D(64,(3,3),padding = \"same\",activation ='relu',strides=(1,1))(conv7_GeN)\n","    conv9_GeN= Conv2D(64,(3,3),padding = \"same\",activation ='relu',strides=(1,1))(conv8_GeN)\n","\n","    conv10_GeN = Conv2D(64,(3,3),padding = \"same\",activation ='relu',strides=(1,1))(conv9_GeN)\n","    Residual_inter_output= BatchNormalization(momentum = 0.8)(conv10_GeN)\n","\n","    # Take the sum of the output from the pre-residual block(gen1) and the post-residual block(gen2)\n","    Residual_output = Add()([Residual_inter_output, conv1_GeN])\n","\n","    # Add an upsampling block\n","    conv11_GeN = UpSampling2D(size=(2,2))(Residual_output) \n","    conv12_GeN= Conv2D(256,(3,3),padding = \"same\",activation ='relu',strides=(1,1))(conv11_GeN)\n","    \n","    \n","    # Add another upsampling block\n","    conv13_GeN = UpSampling2D(size=(2,2))(conv12_GeN)\n","    conv14_GeN= Conv2D(256,(3,3),padding = \"same\",activation ='relu',strides=(1,1))(conv13_GeN)\n","\n","    # Output convolution layer\n","    conv15_GeN= Conv2D(1,(5,5),padding = \"same\",activation ='sigmoid',strides=(1,1))(conv14_GeN)\n","\n","    # Keras model\n","    model = Model(inputs=[input_layer], outputs=[conv15_GeN], name='generator')\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-08T16:25:58.170347Z","iopub.status.busy":"2022-10-08T16:25:58.169982Z","iopub.status.idle":"2022-10-08T16:25:58.184119Z","shell.execute_reply":"2022-10-08T16:25:58.183135Z","shell.execute_reply.started":"2022-10-08T16:25:58.170316Z"},"id":"YtV2vIrYHEMK","trusted":true},"outputs":[],"source":["#Building discriminator network\n","\n","def build_discriminator():\n","  \n","    leakyrelu_alpha = 0.2\n","    input_shape = (128,128,2)\n","\n","    input_layer = Input(shape=input_shape)\n","\n","    # Add the first convolution block\n","    dis1 = Conv2D(64,(3,3), strides=1, padding='same')(input_layer)\n","    dis1 = LeakyReLU(alpha=leakyrelu_alpha)(dis1)\n","\n","    # Add the 2nd convolution block\n","    dis2 = Conv2D(64,(3,3), strides=2, padding='same')(dis1)\n","    dis2 = LeakyReLU(alpha=leakyrelu_alpha)(dis2)\n","    dis2 = BatchNormalization(momentum = 0.8)(dis2)\n","\n","    # Add the third convolution block\n","    dis3 = Conv2D(128,(3,3), strides=1,padding = 'same')(dis2)\n","    dis3 = LeakyReLU(alpha=leakyrelu_alpha)(dis3)\n","    dis3 = BatchNormalization(momentum = 0.8)(dis3)\n","\n","    # Add the fourth convolution block\n","    dis4 = Conv2D(128,(3,3), strides=2, padding = 'same')(dis3)\n","    dis4 = LeakyReLU(alpha=leakyrelu_alpha)(dis4)\n","    dis4 = BatchNormalization(momentum = 0.8)(dis4)\n","\n","    # Add the fifth convolution block\n","    dis5 = Conv2D(256,(3,3), strides=1,padding='same')(dis4)\n","    dis5 = LeakyReLU(alpha=leakyrelu_alpha)(dis5)\n","    dis5 = BatchNormalization(momentum = 0.8)(dis5)\n","\n","    # Add the sixth convolution block\n","    dis6 = Conv2D(256,(3,3), strides=2, padding = 'same')(dis5)\n","    dis6 = LeakyReLU(alpha=leakyrelu_alpha)(dis6)\n","    dis6 = BatchNormalization(momentum = 0.8)(dis6)\n","\n","    # Add the seventh convolution block\n","    dis7 = Conv2D(512,(3,3), strides=1,padding='same')(dis6)\n","    dis7 = LeakyReLU(alpha=leakyrelu_alpha)(dis7)\n","    dis7 = BatchNormalization(momentum = 0.8)(dis7)\n","\n","    # Add the eight convolution block\n","    dis8 = Conv2D(512,(3,3), strides=2, padding = 'same')(dis7)\n","    dis8 = LeakyReLU(alpha=leakyrelu_alpha)(dis8)\n","    dis8 = BatchNormalization(momentum = 0.8)(dis8)\n","\n","    # Add a dense layer\n","    flat = keras.layers.Flatten()(dis8)\n","    dis9 = Dense(units=1024)(flat)\n","    dis9 = LeakyReLU(alpha=0.2)(dis9)\n","\n","    # Last dense layer - for classification\n","    output = Dense(units=1, activation='sigmoid')(dis9)\n","\n","    model = Model(inputs=[input_layer], outputs=[output], name='discriminator')\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-08T16:25:59.061302Z","iopub.status.busy":"2022-10-08T16:25:59.060596Z","iopub.status.idle":"2022-10-08T16:25:59.068384Z","shell.execute_reply":"2022-10-08T16:25:59.067231Z","shell.execute_reply.started":"2022-10-08T16:25:59.061267Z"},"id":"jNb3mCHWwPiQ","trusted":true},"outputs":[],"source":["# Importing Pretrained weights of Imagenet data set in VGG19 architecture at 13th layer\n","\n","def build_vgg():\n","    \"\"\"Build VGG network to extract image features \"\"\"\n","    grayImage = (128,128,3)\n","\n","    vgg = keras.applications.VGG19(include_top = False ,  input_shape = grayImage , weights=\"imagenet\")\n","    features = vgg.get_layer(index = 13).output\n","    #features = vgg.output\n","    model = keras.Model(inputs=[vgg.inputs], outputs=[features])\n","    return model\n","\n","        \n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"t0OYGwgTQllG"},"source":["### Model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-08T17:17:14.073888Z","iopub.status.busy":"2022-10-08T17:17:14.073103Z","iopub.status.idle":"2022-10-08T17:17:14.832279Z","shell.execute_reply":"2022-10-08T17:17:14.831294Z","shell.execute_reply.started":"2022-10-08T17:17:14.073846Z"},"id":"Q5RGUSet8oT1","outputId":"993823be-651f-49be-ccc0-c2c479e96c84","trusted":true},"outputs":[],"source":["# Building Adverserial (combination of generator and discriminator) network\n","\n","mode = 'train'\n","\n","epochs = 30\n","batch_size = 20\n","\n","common_optimizer = Adam(0.0002, 0.5)\n","low_resolution_shape = (32, 32, 1)\n","high_resolution_shape = (128, 128,1)\n","\n","vgg = build_vgg()\n","vgg.trainable = False\n","vgg.compile(loss='mae', optimizer=common_optimizer, metrics=['accuracy'])\n","\n","# Build and compile the discriminator network\n","discriminator = build_discriminator()\n","discriminator.compile(loss='mae', optimizer=common_optimizer, metrics=['accuracy'])\n","\n","# Build the generator network\n","generator = build_generator()\n","\n","\"\"\"\n","Build and compile the adversarial model\n","\"\"\"\n","\n","# Input layers for high-resolution and low-resolution images\n","input_high_resolution = Input(shape=high_resolution_shape)\n","input_low_resolution = Input(shape=low_resolution_shape)\n","#Input_final_to_discriminator=Input(shape=Input_to_discriminator)\n","\n","# Generate high-resolution images from low-resolution images\n","generated_high_resolution_images = generator(input_low_resolution)\n","\n","rgbImage=Concatenate()([generated_high_resolution_images,generated_high_resolution_images,generated_high_resolution_images])\n","\n","# Extract feature maps of the generated images\n","features = vgg(rgbImage)\n","\n","# Freeze the discriminator for while training the adversarial model\n","discriminator.trainable = False\n","\n","final_input_to_discriminator=Concatenate()([input_high_resolution,input_high_resolution])\n","# Get the probability of generated high-resolution images\n","probs = discriminator(final_input_to_discriminator)\n","\n","# Create and compile an adversarial model\n","adversarial_model = Model([input_low_resolution, input_high_resolution], [probs,features])\n","adversarial_model.compile(loss=['binary_crossentropy', 'mae'], loss_weights=[1e-3, 1], optimizer=common_optimizer)\n","\n","generator.summary()\n","discriminator.summary()\n","adversarial_model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-08T17:17:14.835100Z","iopub.status.busy":"2022-10-08T17:17:14.834173Z","iopub.status.idle":"2022-10-08T17:17:14.877997Z","shell.execute_reply":"2022-10-08T17:17:14.876962Z","shell.execute_reply.started":"2022-10-08T17:17:14.835062Z"},"id":"hDRAId1u_-Hs","outputId":"1a45c877-66de-4b1c-b9f3-b70ae13d6dbe","trusted":true},"outputs":[],"source":["#Importing high reolution images(ground truth) and splitting data for training and testing\n","\n","low_resolution_images = input_GAN\n","inverted_high_resolution_img =np.load('../input/dataset-new/High_res.npy',allow_pickle=True)\n","\n","low_resolution_images_train,low_resolution_images_test,inverted_high_resolution_img_train,inverted_high_resolution_img_test = train_test_split(low_resolution_images,inverted_high_resolution_img,train_size= 0.8,test_size=0.20,shuffle=False)\n","print(low_resolution_images_train.shape)\n","print(inverted_high_resolution_img_test.shape)\n","print(low_resolution_images.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-08T17:17:14.880238Z","iopub.status.busy":"2022-10-08T17:17:14.879297Z","iopub.status.idle":"2022-10-08T17:17:15.263142Z","shell.execute_reply":"2022-10-08T17:17:15.262054Z","shell.execute_reply.started":"2022-10-08T17:17:14.880190Z"},"id":"msChHHxLF8aL","outputId":"5c0b3390-440e-4cce-a1e0-ea13554fb52a","trusted":true},"outputs":[],"source":["#temporary modification of ground truth data to be passed in VGG19 network\n","\n","\n","inverted_high_resolution_img1=np.expand_dims(inverted_high_resolution_img_train,axis=3)\n","inverted_high_resolution_img2=np.concatenate((inverted_high_resolution_img1,inverted_high_resolution_img1,inverted_high_resolution_img1),axis=3)\n","\n","\n","#UPSCALING OF 32x32: \n","resized_low_resolution_image = resize(low_resolution_images, (945,128,128,1),order =0,preserve_range=True, anti_aliasing=False)\n","print(resized_low_resolution_image.shape)\n","print(inverted_high_resolution_img.shape)\n","expanded = np.expand_dims(inverted_high_resolution_img,axis=3)\n","discrim_realdata= np.concatenate((resized_low_resolution_image,expanded),axis=3)\n","print(discrim_realdata.shape)\n","discrim_realdata_train=discrim_realdata[:756]\n","print(discrim_realdata_train.shape)\n","discrim_realdata_test=discrim_realdata[756:]\n","print(discrim_realdata_test.shape)\n","\n","#SPLIT THE RESIZED DATA TO TRAIN AND TEST\n","resized_low_resolution_image_train = resized_low_resolution_image[:756]\n","resized_low_resolution_image_test = resized_low_resolution_image[756:]\n","print(resized_low_resolution_image_train.shape)\n","print(resized_low_resolution_image_test.shape)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-08T17:17:15.266125Z","iopub.status.busy":"2022-10-08T17:17:15.265421Z","iopub.status.idle":"2022-10-08T17:25:10.687446Z","shell.execute_reply":"2022-10-08T17:25:10.686402Z","shell.execute_reply.started":"2022-10-08T17:17:15.266081Z"},"id":"DDE-NI390sTN","outputId":"a927b0be-88fc-4135-8003-8fa339ba19e8","trusted":true},"outputs":[],"source":["# Training Adverserial Model\n","def just_train():\n","    \n","    train_batches = int(np.ceil(len(low_resolution_images_train)/batch_size))-1\n","    \n","    for epoch in range(epochs):\n","        \n","        for i in  range(train_batches):\n","   \n","            beg = i*batch_size\n","            end = (i+1)*batch_size\n","\n","            # Generate high-resolution images from low-resolution images\n","            generated_high_resolution_images = generator.predict(low_resolution_images_train[beg:end])\n","            discrim_fakedata = np.concatenate((resized_low_resolution_image_train[beg:end],generated_high_resolution_images),axis=3)\n","                          \n","            # Generate batch of real and fake labels\n","            real_labels = np.ones((batch_size, 1))*0.95\n","            fake_labels = np.ones((batch_size,  1))*0.05\n","                          \n","            # Train the discriminator network on real and fake images\n","            d_loss_real = discriminator.train_on_batch(discrim_realdata[beg:end], real_labels)\n","            d_loss_fake = discriminator.train_on_batch(discrim_fakedata, fake_labels)\n","\n","            # Calculate total discriminator loss\n","            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n","\n","            image_features = vgg.predict(inverted_high_resolution_img2[beg:end])\n","\n","            # Train the generator network\n","            g_loss = adversarial_model.train_on_batch([low_resolution_images_train[beg:end],inverted_high_resolution_img_train[beg:end]], [real_labels,image_features])\n","\n","\n","            print(\"Epoch {} : g_loss: {} , d_loss: {}\".format(epoch , g_loss[0] , d_loss[0]))\n","\n","    \n","if mode == 'train':\n","        just_train()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-08T17:25:12.759840Z","iopub.status.busy":"2022-10-08T17:25:12.759453Z","iopub.status.idle":"2022-10-08T17:25:13.236604Z","shell.execute_reply":"2022-10-08T17:25:13.235496Z","shell.execute_reply.started":"2022-10-08T17:25:12.759807Z"},"id":"gUwAK3f9_8Lm","outputId":"d7a51877-cf2f-4bc9-999a-1eb00353486e","trusted":true},"outputs":[],"source":["# Predict on test data and plotting interactively\n","\n","generated_images = generator.predict(low_resolution_images_test)\n","\n","def plot_bridge4(i):\n","    fig,ax = pyplot.subplots()\n","    im4 = pyplot.imshow(generated_images[i].reshape(128,128), cmap='gray')\n","    pyplot.axis('off')\n","    \n","    pyplot.show()\n","\n","interact(plot_bridge4, i=(0, len(generated_images)-1))"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":2516411,"sourceId":4270791,"sourceType":"datasetVersion"}],"dockerImageVersionId":30262,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
